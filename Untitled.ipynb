{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import glob, os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from torch.utils import data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD = 0\n",
    "UNK = 1\n",
    "BOS = 2\n",
    "EOS = 3\n",
    "\n",
    "PAD_WORD = '<blank>'\n",
    "UNK_WORD = '<unk>'\n",
    "BOS_WORD = '<s>'\n",
    "EOS_WORD = '</s>'\n",
    "\n",
    "\n",
    "def np_encode_string(s, char0 = ord(' ')):\n",
    "    \"\"\"converts a string into a numpy array of bytes\n",
    "    (char0 - 1) is subtracted from all bytes values (0 is used for PAD)\n",
    "    string is pre-pended with BOS and post-pended with EOS\"\"\"\n",
    "    chars = np.array(list(s), dtype='S1').view(np.uint8)\n",
    "    # normalize to 1 - 96, 0 being PAD\n",
    "    chars = chars - char0 + 1\n",
    "\n",
    "    chars = np.insert(chars, 0, BOS)\n",
    "    chars = np.insert(chars, len(chars), EOS)\n",
    "    return chars\n",
    "\n",
    "def np_decode_string(chars, char0 = ord(' ')):\n",
    "    \"\"\"converts a numpy array of bytes into a UTF-8 string\n",
    "    (char0 - 1) is added to all bytes values (0 is used for PAD)\n",
    "    BOS/EOS are removed before utf-8 decoding\"\"\"\n",
    "    chars = chars.astype(np.uint8)\n",
    "    chars = chars + char0 - 1\n",
    "    chars = chars[:-1]\n",
    "    chars = chars.tobytes()\n",
    "    s = chars.decode('UTF-8')\n",
    "    return s\n",
    "\n",
    "class LazyFileMathDataset(data.Dataset):\n",
    "    \"\"\"Stream loads math dataset file in a lazy way (optional)\n",
    "    pandas is used for naive streaming as Python doesn't provide any better tool for that critical feature\"\"\"\n",
    "    def __init__(self, file, lazy_load=False, max_elements=None, log=False):\n",
    "        self.file = Path(file)\n",
    "        self.lazy_load = lazy_load\n",
    "        self.max_elements = max_elements\n",
    "\n",
    "        fn = self.file.name.replace(\".txt\", \"\")\n",
    "        self.category, self.module = fn.split(\"__\")\n",
    "\n",
    "        if not self.lazy_load:\n",
    "            self.build_dataset()\n",
    "            if log:\n",
    "                print(f\"Initialized MathDataset with file {self.file} (category:{self.category}, module:{self.module}) containing {self.qas.shape[0]} pairs of questions/answers\")\n",
    "        else:\n",
    "            self.qas = None\n",
    "            if log:\n",
    "                print(f\"Initialized MathDataset with file {self.file} (category:{self.category}, module:{self.module}) in lazy mode\")\n",
    "\n",
    "      \n",
    "    def _read_build_dataset(self):\n",
    "        self.df = pd.read_csv(self.file, header=None, sep='\\n', names=['qa'], engine='c')\n",
    "        self._build_dataset()\n",
    "    \n",
    "    def _build_dataset(self):\n",
    "        if self.max_elements is not None:\n",
    "            self.df_max = self.df.iloc[0:self.max_elements*2]\n",
    "        else:\n",
    "            self.df_max = self.df\n",
    "        self.questions = self.df_max[0::2]\n",
    "        self.questions.reset_index(inplace=True, drop=True)\n",
    "        self.questions.rename(columns={ \"qa\" : \"questions\" }, inplace=True)\n",
    "        self.answers = self.df_max[1::2]\n",
    "        self.answers.reset_index(inplace=True, drop=True)\n",
    "        self.answers.rename(columns={ \"qa\" : \"answers\" }, inplace=True)\n",
    "        self.qas = pd.concat([self.questions, self.answers], axis=1)\n",
    "        \n",
    "    def set_max_elements(self, max_elements):\n",
    "        self.max_elements = max_elements\n",
    "        if self.qas is None:\n",
    "            self._read_build_dataset()\n",
    "        else:\n",
    "            self._build_dataset()\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        if self.qas is None:\n",
    "            self._read_build_dataset()            \n",
    "        question, answer = self.qas.iloc[idx]\n",
    "        return {\n",
    "            \"q\": question, \"q_enc\": np_encode_string(question),\n",
    "            \"a\": answer, \"a_enc\": np_encode_string(answer),\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.qas is None:\n",
    "           self._read_build_dataset() \n",
    "        return self.qas.shape[0]\n",
    "    \n",
    "\n",
    "class MathDatasetManager(data.Dataset):\n",
    "    \"\"\"A Math Dataset manager starting at root directory (like v1.0) to extract files and build torch datasets\n",
    "    in a lazy loading and streamed way based on specific types/categories/modules presented in paper.\n",
    "    \n",
    "    It indexes difficulty/use-case types:\n",
    "        - train-easy\n",
    "        - train-medium\n",
    "        - train-hard\n",
    "        - interpolate\n",
    "        - extrapolate\n",
    "    \n",
    "    and all categories:\n",
    "        - algebra\n",
    "        - numbers\n",
    "        - polynomials\n",
    "        - arithmetic\n",
    "        - measurement\n",
    "        - comparison\n",
    "        - probability\n",
    "        - calculus\n",
    "        \n",
    "    and all modules in those categories:\n",
    "        - mul\n",
    "        - add_or_sub_in_base\n",
    "        - simplify_surd\n",
    "        - mul_div_multiple\n",
    "        - mixed\n",
    "        - nearest_integer_root\n",
    "        - div\n",
    "        - add_or_sub\n",
    "        - add_sub_multiple\n",
    "        - add_sub_multiple_longer\n",
    "        - mul_div_multiple_longer\n",
    "        - div_big\n",
    "        - mul_big\n",
    "        - mixed_longer\n",
    "        - add_or_sub_big\n",
    "        - etc...\n",
    "    \"\"\"\n",
    "    def __init__(self, root_dir, log=False):\n",
    "        self.root_dir = Path(root_dir)\n",
    "\n",
    "        self.dirs = {\n",
    "            \"train-easy\" : self.root_dir / \"train-easy\",\n",
    "            \"train-medium\" : self.root_dir / \"train-medium\",\n",
    "            \"train-hard\" : self.root_dir / \"train-hard\",\n",
    "            \"interpolate\" : self.root_dir / \"interpolate\",\n",
    "            \"extrapolate\" : self.root_dir / \"extrapolate\",\n",
    "        }\n",
    "        \n",
    "        self.dfs = {}\n",
    "                \n",
    "        for k, dir in self.dirs.items():\n",
    "            files = [ff for ff in glob.glob(str(dir) + \"/**/*.txt\", recursive=True)]\n",
    "            for f in files:\n",
    "                ds = LazyFileMathDataset(f, lazy_load = True, log=log)\n",
    "                if ds.category not in self.dfs:\n",
    "                    self.dfs[ds.category] = {}\n",
    "                if ds.module not in self.dfs[ds.category]:\n",
    "                    self.dfs[ds.category][ds.module] = {\n",
    "                        \"easy\" : {}, \"medium\" : {}, \"hard\" : {},\n",
    "                        \"interpolate\": {}, \"extrapolate\": {}\n",
    "                    }\n",
    "\n",
    "                self.dfs[ds.category][ds.module][k] = ds                    \n",
    "\n",
    "        print(f\"initialized MultiFilesMathDataset with categories {list(self.dfs.keys())} and types {list(self.dirs.keys())}\")\n",
    "\n",
    "    def get_types(self):\n",
    "        \"\"\"retrieves all math typesfor this multi-file dataset\"\"\"\n",
    "        return self.dirs.keys()            \n",
    "        \n",
    "    def get_categories(self):\n",
    "        \"\"\"retrieves all math problem categories in this multi-file dataset\"\"\"\n",
    "        return self.dfs.keys()\n",
    "    \n",
    "    def get_modules_for_category(self, c):\n",
    "        \"\"\"retrieves all mathematical modules in a math problem category\"\"\"\n",
    "        return self.dfs[c].keys()\n",
    "    \n",
    "    def _build_datasets_from_category(self, category, typ, max_elements=None):\n",
    "        ds = []\n",
    "        for k, m in self.dfs[category].items():\n",
    "            if typ in m:\n",
    "                m[typ].set_max_elements(max_elements)\n",
    "                ds.append(m[typ])\n",
    "                print(f\"added module {category}/{k}/{typ}\")\n",
    "        return ds\n",
    "        \n",
    "    def build_dataset_from_category(self, category, typ, max_elements=None):\n",
    "        \"\"\"Build a dataset for all modules in a category\"\"\"\n",
    "        print(f\"adding category {category}/../{typ}\")\n",
    "        ds = self._build_datasets_from_category(category, typ, max_elements=max_elements)\n",
    "        return data.ConcatDataset(ds)\n",
    "    \n",
    "    def build_dataset_from_categories(self, categories, typ, max_elements=None):\n",
    "        \"\"\"Build a dataset for all modules in several categories\"\"\"\n",
    "        ds = []\n",
    "        for c in categories:\n",
    "            print(f\"adding category {c}/../{typ}\")\n",
    "            dss = self._build_datasets_from_category(c, typ, max_elements=max_elements)\n",
    "            ds.extend(dss)\n",
    "        return data.ConcatDataset(ds)\n",
    "\n",
    "    def build_dataset_from_module(self, category, module, typ, max_elements=None):\n",
    "        \"\"\"Build a dataset from a single module in a category\"\"\"\n",
    "        self.dfs[category][module][typ].set_max_elements(max_elements)\n",
    "        return self.dfs[category][module][typ]\n",
    "\n",
    "    def build_dataset_from_modules(self, category, modules, typ, max_elements=None):\n",
    "        \"\"\"Build a dataset from several modules in a category\"\"\"\n",
    "        ds = []\n",
    "        for module in modules:\n",
    "            self.dfs[category][module][typ].set_max_elements(max_elements)\n",
    "            ds.append(self.dfs[category][module][typ])\n",
    "        return data.ConcatDataset(ds)\n",
    "    \n",
    "    def build_dataset_from_categories_and_types(self, categories, types, max_elements=None):\n",
    "        \"\"\"Build a dataset for all modules in several categories\"\"\"\n",
    "        ds = []\n",
    "        for c in categories:\n",
    "            for typ in types:\n",
    "                try:\n",
    "                    print(f\"adding category {c}/../{typ}\")\n",
    "                    dss = self._build_datasets_from_category(c, typ, max_elements=max_elements)\n",
    "                    ds.extend(dss)\n",
    "                except:\n",
    "                    continue\n",
    "        return data.ConcatDataset(ds)\n",
    "    \n",
    "    \n",
    "def question_answer_to_batch_collate_fn(qas):\n",
    "    ''' Gather + Pad the question/answer to the max seq length in batch '''\n",
    "\n",
    "    max_q_len = max(len(qa[\"q_enc\"]) for qa in qas)\n",
    "    max_a_len = max(len(qa[\"a_enc\"]) for qa in qas)\n",
    "\n",
    "    batch_qs = []\n",
    "    batch_as = []\n",
    "    batch_pos = []\n",
    "    for qa in qas:\n",
    "      batch_qs.append(np.pad(qa[\"q_enc\"], (0, max_q_len - len(qa[\"q_enc\"])), mode='constant', constant_values=PAD))\n",
    "      batch_as.append(np.pad(qa[\"a_enc\"], (0, max_a_len - len(qa[\"a_enc\"])), mode='constant', constant_values=PAD))\n",
    "    \n",
    "    batch_qs = torch.LongTensor(batch_qs)\n",
    "    batch_as = torch.LongTensor(batch_as)\n",
    "\n",
    "    return batch_qs, batch_as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialized MultiFilesMathDataset with categories ['numbers', 'algebra', 'probability', 'arithmetic', 'comparison', 'polynomials', 'measurement', 'calculus'] and types ['train-easy', 'train-medium', 'train-hard', 'interpolate', 'extrapolate']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/frame.py:4238: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "mdsmgr = MathDatasetManager(\"mathematics_dataset-v1.0\")\n",
    "\n",
    "# ds = mdsmgr.build_dataset_from_categories_and_types(list(mdsmgr.get_categories())[:1], list(mdsmgr.get_types())[:1])\n",
    "ds = mdsmgr.build_dataset_from_module('arithmetic', 'add_or_sub', 'train-easy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data.DataLoader(\n",
    "    ds, batch_size=128, shuffle=True,#, num_workers=1,#num_workers=4,\n",
    "    collate_fn=question_answer_to_batch_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_loader:\n",
    "    batch_qs, batch_as = i\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformer.Models import Transformer\n",
    "import transformer\n",
    "# ASCII CHARS\n",
    "VOCAB_SIZE = 95\n",
    "# questions have less than 160 chars\n",
    "MAX_QUESTION_SZ = 160\n",
    "# answers have less than 30 chars\n",
    "MAX_ANSWER_SZ = 30\n",
    "\n",
    "num_layers = 1\n",
    "num_heads = 1\n",
    "key_dimension = 16\n",
    "value_dimension = 16\n",
    "dropout = 0.1\n",
    "n_position = 160\n",
    "d_char_vec = 32\n",
    "model_dimension = 32\n",
    "inner_dimension = 124\n",
    "n_trg_position = MAX_ANSWER_SZ\n",
    "n_src_position = MAX_QUESTION_SZ\n",
    "\n",
    "\n",
    "model = transformer.Models.Transformer(n_src_vocab=VOCAB_SIZE + 1, n_trg_vocab=VOCAB_SIZE+1, src_pad_idx=0, trg_pad_idx=0,\n",
    "                   d_char_vec=d_char_vec, d_model=d_char_vec, d_inner=inner_dimension, n_layers=num_layers,\n",
    "                   n_head=num_heads, d_k=key_dimension, d_v=value_dimension, dropout=dropout,\n",
    "                   n_trg_position=n_trg_position, n_src_position=n_src_position,\n",
    "                   trg_emb_prj_weight_sharing=True, emb_src_trg_weight_sharing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_hid, n_position=200):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "\n",
    "        # Not a parameter\n",
    "        self.register_buffer('pos_table', self._get_sinusoid_encoding_table(n_position, d_hid))\n",
    "\n",
    "    def _get_sinusoid_encoding_table(self, n_position, d_hid):\n",
    "        ''' Sinusoid position encoding table '''\n",
    "        # TODO: make it with torch instead of numpy\n",
    "\n",
    "        def get_position_angle_vec(position):\n",
    "            return [position / np.power(10000, 2 * (hid_j // 2) / d_hid) for hid_j in range(d_hid)]\n",
    "\n",
    "        sinusoid_table = np.array([get_position_angle_vec(pos_i) for pos_i in range(n_position)])\n",
    "        sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])  # dim 2i\n",
    "        sinusoid_\n",
    "        table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])  # dim 2i+1\n",
    "\n",
    "        return torch.FloatTensor(sinusoid_table).unsqueeze(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pos_table[:, :x.size(1)].clone().detach()\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    \n",
    "    def __init__(self, conv_layers=4, d_char_vec=512, n_vocab=96, kernel_size=4, dropout=0.1, padding=1, \n",
    "                 src_embedding=None, trg_embedding=None, src_position_enc=None, trg_position_enc=None, pad_idx=0):\n",
    "        \n",
    "        super(Critic, self).__init__()\n",
    "        \n",
    "        self.src_word_emb = src_embedding if src_embedding != None else nn.Embedding(n_vocab, d_char_vec, padding_idx=pad_idx)\n",
    "        self.trg_word_emb = trg_embedding if trg_embedding != None else nn.Embedding(n_vocab, d_char_vec, padding_idx=pad_idx)\n",
    "        \n",
    "        self.src_position_enc = src_position_enc if src_position_enc != None else PositionalEncoding(d_char_vec, n_position=MAX_QUESTION_SIZE)\n",
    "        self.trg_position_enc = trg_position_enc if trg_position_enc != None else PositionalEncoding(d_char_vec, n_position=MAX_ANSWER_SIZE)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        self.conv_layers = [nn.Conv1d(in_channels=d_char_vec, out_channels=d_char_vec, kernel_size=kernel_size, padding=padding) for _ in range(conv_layers)]\n",
    "        self.value_layer = nn.Linear(d_char_vec, 1)\n",
    "        \n",
    "    def forward(self, src_seq, trg_seq):\n",
    "        \n",
    "        batch_sz, max_src_pos, max_trg_pos = src_seq.shape[0], src_seq.shape[1], trg_seq.shape[1]\n",
    "        src_seq_pad = torch.cat((src_seq, torch.zeros((batch_sz, MAX_QUESTION_SIZE-max_src_pos), dtype=torch.int64)), dim=1)\n",
    "        trg_seq_pad = torch.cat((trg_seq, torch.zeros((batch_sz, MAX_ANSWER_SIZE-max_trg_pos), dtype=torch.int64)), dim=1)\n",
    "        src_emb = self.dropout(self.src_position_enc(self.src_word_emb(src_seq_pad)))\n",
    "        trg_emb = self.dropout(self.trg_position_enc(self.trg_word_emb(trg_seq_pad)))\n",
    "        \n",
    "        x = torch.cat((src_emb, trg_emb), dim=1)\n",
    "        conv_out = torch.transpose(x, 1, 2).contiguous()\n",
    "        for conv in self.conv_layers:\n",
    "            conv_out = conv(conv_out)\n",
    "        conv_out = torch.mean(F.relu(conv_out), dim=2)\n",
    "        output = self.value_layer(conv_out)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer.Models import Transformer\n",
    "\n",
    "# ASCII CHARACTERS\n",
    "VOCAB_SIZE = 95\n",
    "# questions have less than 160 chars\n",
    "MAX_QUESTION_SIZE = 160\n",
    "# answers have less than 30 chars\n",
    "MAX_ANSWER_SIZE = 30\n",
    "\n",
    "class Policy_Network(nn.Module):\n",
    "#     def __init__(self, num_layers = 6, num_heads = 8, key_dimension = 64, \n",
    "    def __init__(self, num_layers = 1, num_heads = 2, key_dimension = 64, \n",
    "                 value_dimension = 64, dropout = 0.1, n_position = 160, \n",
    "                 d_char_vec = 512, inner_dimension = 2048, \n",
    "                 n_trg_position = MAX_ANSWER_SIZE, n_src_position = MAX_QUESTION_SIZE, padding = 1,\n",
    "                critic_num_layers=4, critic_kernel_size=4, critic_padding=1, model=None):\n",
    "        \n",
    "        super(Policy_Network, self).__init__()\n",
    "        \n",
    "        self.action_transformer = Transformer(n_src_vocab=VOCAB_SIZE + 1, n_trg_vocab=VOCAB_SIZE+1, src_pad_idx=0, trg_pad_idx=0,\n",
    "                               d_char_vec=d_char_vec, d_model=d_char_vec, d_inner=inner_dimension, n_layers=num_layers,\n",
    "                               n_head=num_heads, d_k=key_dimension, d_v=value_dimension, dropout=dropout,\n",
    "                               n_trg_position=n_trg_position, n_src_position=n_src_position,\n",
    "                               trg_emb_prj_weight_sharing=True, emb_src_trg_weight_sharing=True) if model == None else model\n",
    "        \n",
    "        \n",
    "#         output of action transformer for state is shape (B X MAX_QUESTION_SZ*2 + MAX_ANSWQ_SZ X WORD_EMB)\n",
    "#         input to convolution layer is B X WORD_EMB X MAX_QUESTION_SIZE*2 + MAX_ANSWER_SIZE\n",
    "        self.value_head = Critic(conv_layers=critic_num_layers, d_char_vec=d_char_vec, kernel_size=critic_kernel_size,\n",
    "                                n_vocab=VOCAB_SIZE+1, dropout=dropout, padding=critic_padding, \n",
    "                                src_embedding=self.action_transformer.encoder.src_word_emb, \n",
    "                                trg_embedding=self.action_transformer.decoder.trg_word_emb, \n",
    "                                 src_position_enc=self.action_transformer.encoder.position_enc, \n",
    "                                 trg_position_enc=self.action_transformer.decoder.position_enc)\n",
    "        \n",
    "    def forward(self, src_seq, trg_seq):\n",
    "        \n",
    "        action_prob = self.action_transformer(src_seq, trg_seq)\n",
    "        action_prob = action_prob[:, -1, :]\n",
    "        state_values = self.value_head(src_seq, trg_seq)\n",
    "        \n",
    "        return action_prob, state_values\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, device='cpu'):\n",
    "        self.device=device\n",
    "        self.eps = np.finfo(np.float32).eps.item()\n",
    "    \n",
    "    def calc_reward(self, actions_pred, actions, ignore_index=0):\n",
    "        # 1 if character is correct\n",
    "        return (actions_pred==actions).float()\n",
    "    \n",
    "    \n",
    "    def train_mle_epoch(self, training_data, model, optimizer):\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    def train_policy_epoch(self, training_data, model, gamma, optimizer):\n",
    "        \n",
    "        model.train()\n",
    "        ignore_index = model.action_transformer.trg_pad_idx\n",
    "        \n",
    "    #     sample batch of questions and answers\n",
    "        for batch_idx, batch in enumerate(tqdm(training_data, mininterval=2, leave=False)):\n",
    "            batch_qs, batch_as = map(lambda x: x.to(self.device), batch)\n",
    "            batch_size = batch_qs.shape[0]\n",
    "            to_store = [[]*batch_size]\n",
    "            current_as = batch_as[:, :1]\n",
    "            complete = torch.ones((batch_size, 1))\n",
    "            rewards = torch.zeros((batch_size, 0))\n",
    "            values = torch.zeros((batch_size, 0))\n",
    "            log_probs = torch.zeros((batch_size, 0))\n",
    "            advantages_mask = torch.ones((batch_size, 0))\n",
    "            for t in range(1, MAX_ANSWER_SIZE):\n",
    "                advantages_mask = torch.cat((advantages_mask, complete), dim=1)\n",
    "                action_probs, curr_values = model(batch_qs, current_as)\n",
    "                m = Categorical(F.softmax(action_probs, dim=-1))\n",
    "                actions = m.sample().contiguous().view(-1, 1)\n",
    "                \n",
    "                trg_t = batch_as[:, t].contiguous().view(-1, 1)\n",
    "                \n",
    "                # update decoder output\n",
    "                current_as = torch.cat((current_as, actions), dim=1)\n",
    "                \n",
    "                curr_log_probs = -F.cross_entropy(action_probs, trg_t.view(-1), ignore_index=0, reduction='none').contiguous().view(-1, 1)\n",
    "                \n",
    "                # calculate reward based on character cross entropy\n",
    "                curr_rewards = self.calc_reward(actions, trg_t)\n",
    "                \n",
    "                # update terms\n",
    "                rewards = torch.cat((rewards, curr_rewards), dim=1)\n",
    "                values = torch.cat((values, curr_values), dim=1)\n",
    "                log_probs = torch.cat((log_probs, curr_log_probs), dim=1)\n",
    "                \n",
    "                # if the action taken is EOS or if end of sequence trajectory ends\n",
    "                complete *= (1 - ((actions==EOS) | (trg_t==EOS)).float())\n",
    "            \n",
    "\n",
    "            returns = self.get_returns(rewards, batch_size, gamma)\n",
    "            \n",
    "            advantages = returns - values\n",
    "            advantages *= advantages_mask\n",
    "\n",
    "            policy_losses = (-log_probs * advantages).sum(dim=-1).mean()\n",
    "\n",
    "            value_losses = F.mse_loss(values, rewards, reduction='mean')\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss = policy_losses + value_losses\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    def get_returns(self, rewards, batch_size, gamma):\n",
    "        T = rewards.shape[1]\n",
    "        discounts = torch.tensor(np.logspace(0, T, T, base=gamma, endpoint=False)).view(1, -1)\n",
    "        all_returns = torch.zeros((batch_size, T))\n",
    "        \n",
    "        for t in range(T):\n",
    "            temp = (discounts[:, :T-t]*rewards[:, t:]).sum(dim=-1)\n",
    "            all_returns[:, t] = temp\n",
    "            (all_returns - all_returns.mean(dim=-1).view(-1, 1)) / (all_returns.std(dim=-1).view(-1, 1) + self.eps)\n",
    "    \n",
    "        return all_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main():\n",
    "\n",
    "model = Policy_Network()\n",
    "trainer = Trainer()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5209 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "torch.Size([128, 1])\n",
      "here\n",
      "torch.Size([128, 1])\n",
      "here\n",
      "torch.Size([128, 1])\n",
      "here\n",
      "torch.Size([128, 1])\n",
      "torch.Size([128, 4])\n",
      "torch.Size([128, 4])\n",
      "torch.Size([128, 4])\n",
      "torch.Size([128, 4])\n",
      "torch.Size([128, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 1/5209 [00:37<54:53:04, 37.94s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "torch.Size([128, 1])\n",
      "here\n",
      "torch.Size([128, 1])\n",
      "here\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-8970bb06ffc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train_loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_policy_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.99\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-84-8f218547607d>\u001b[0m in \u001b[0;36mtrain_policy_epoch\u001b[0;34m(self, training_data, model, gamma, optimizer)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0madvantages_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madvantages_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomplete\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                 \u001b[0maction_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_qs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_as\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;31m#                 print(action_probs.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-84-8f218547607d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src_seq, trg_seq)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0maction_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_transformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0maction_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction_prob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mstate_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maction_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-1f49bf8cf0a4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src_seq, trg_seq)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mconv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mconv_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mconv_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train_loader\n",
    "trainer.train_policy_epoch(train_loader, model, .99, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model.value_head.src_word_emb(torch.tensor([0]))[0][:4])\n",
    "\n",
    "# print(model.action_transformer.encoder.src_word_emb(torch.tensor([0]))[0][:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds = data.random_split(x, [int(.9*len(x)), len(x)-int(.9*len(x))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, training_data, optimizer, device, epoch, tb=None, log_interval=100):\n",
    "    model.train()\n",
    "    \n",
    "    total_rewards = 0\n",
    "    n_char_total = 0\n",
    "    n_char_correct = 0\n",
    "    for batch_idx, batch in enumerate(tqdm(training_data, mininterval=2, leave=False)):\n",
    "        \n",
    "        # all in shape [B, MAX_LENGTH] where representation is in integers used in embedding lookup in transformer\n",
    "        batch_qs, batch_qs_pos, batch_as, batch_as_pos = map(lambda x: x.to(device), batch)\n",
    "        \n",
    "        target_as = batch_as[:, 1:]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pred_as = model(batch_qs, batch_qs_pos, batch_as, batch_as_pos)\n",
    "\n",
    "        loss, n_correct = compute_performance(pred_as, gold_as, smoothing=True)    \n",
    "        loss.backward()\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "    \n",
    "        # note keeping\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        non_pad_mask = gold_as.ne(Constants.PAD)\n",
    "        n_char = non_pad_mask.sum().item()\n",
    "        n_char_total += n_char\n",
    "        n_char_correct += n_correct\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input chars are selected from basic ASCII chars\n",
    "VOCAB_SZ = 95\n",
    "# questions have less than 160 chars\n",
    "MAX_QUESTION_SZ = 160\n",
    "# answers have less than 30 chars, need to check this and the above can also just automate with the dataset\n",
    "MAX_ANSWER_SZ = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
