{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch import autograd\n",
    "import torch.distributed as dist\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "# from multiprocessing import SimpleQueue\n",
    "from torch.multiprocessing import Process#, Queue\n",
    "from multiprocessing import Queue, Event, Manager\n",
    "import numpy as np\n",
    "import random\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)\n",
    "torch.manual_seed(1234)\n",
    "value_temp = torch.FloatTensor(np.random.rand(1, 24))\n",
    "hey_temp = torch.LongTensor([np.random.randint(0, 10)])\n",
    "\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mlp(nn.Module):\n",
    "\n",
    "    \n",
    "    def __init__(self, in_dim=24, out_dim=10, dropout_rate=0.0):\n",
    "        super(mlp, self).__init__()\n",
    "        self.h1 = nn.Linear(in_dim, in_dim)\n",
    "        self.h2 = nn.Linear(in_dim, out_dim)\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        pred_logits = self.dropout(self.h2(self.h1(x)))\n",
    "        return F.cross_entropy(pred_logits, y), pred_logits\n",
    "\n",
    "import copy    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner(nn.Module):\n",
    "    \n",
    "    def __init__(self, process, world_size, in_dim, out_dim=1, dropout_rate=0.0, optimizer=optim.Adam, lr=1e-2):\n",
    "        super(Learner, self).__init__()\n",
    "        self.model = mlp(in_dim=in_dim, dropout_rate=dropout_rate)\n",
    "\n",
    "        if process == 0:\n",
    "            self.optimizer = optimizer(self.model.parameters(), lr=lr)#optim.Adam(self.parameters(), lr=1e-6)\n",
    "        self.meta_optimizer = optim.SGD(self.model.parameters(), 0.1)\n",
    "        self.process = process\n",
    "        self.world_size = world_size\n",
    "        self.device='cpu'\n",
    "    \n",
    "    def _update_net(self, new_state_dict):\n",
    "        self.model.load_state_dict(new_state_dict)\n",
    "        self.model.to(self.device)\n",
    "        \n",
    "    def _hook_grads(self, all_grads):\n",
    "        hooks = []\n",
    "        for i, v in enumerate(self.model.parameters()):\n",
    "            def closure():\n",
    "                ii = i\n",
    "                return lambda grad: all_grads[ii]\n",
    "            \n",
    "            hooks.append(v.register_hook(closure()))\n",
    "        return hooks\n",
    "        \n",
    "        \n",
    "    def _write_grads(self, original_state_dict, all_grads):\n",
    "        self.model.load_state_dict(original_state_dict)\n",
    "        print('after meta gradient and loaded batch')\n",
    "        print(self.model.state_dict()['h1.weight'][0, :])#(value_temp, hey_temp)[0])\n",
    "        self.model.train()\n",
    "        self.optimizer.zero_grad()\n",
    "        dummy_loss, _ = self.model(torch.FloatTensor(torch.zeros(2, 24)), torch.LongTensor(np.random.randint(0, 5, (2))))\n",
    "        hooks = self._hook_grads(all_grads)\n",
    "        \n",
    "        \n",
    "        dummy_loss.backward()\n",
    "        self.optimizer.step()\n",
    "        print('after meta gradient batch')\n",
    "        print(self.model.state_dict()['h1.weight'][0, :])#(value_temp, hey_temp)[0])\n",
    "        \n",
    "        for h in hooks:\n",
    "            h.remove()\n",
    "            \n",
    "    def forward(self, num_updates, data_queue, data_event, model_queue, process_event):\n",
    "        while(True):\n",
    "            data_event.wait()\n",
    "            data = data_queue.get()\n",
    "            dist.barrier()\n",
    "            data_event.clear()\n",
    "            if self.process == 0:\n",
    "                print('at top')\n",
    "                print(self.model.state_dict()['h1.weight'][0, :])\n",
    "#             new_state_dict = getattr(model_queue, 'queue')[0]\n",
    "#             new_state_dict = model_queue[0]#['params']\n",
    "#             if process == 0:\n",
    "#             original_state_dict = {}#copy.deepcopy(self.model.state_dict())\n",
    "            \n",
    "#             for k, v in self.model.state_dict().items():\n",
    "#                 temp_v = v.clone().detach()\n",
    "#                 if original_state_dict[k] = v.clone().detach()\n",
    "#                 dist.broadcast(temp_v, src=0, async_op=True)\n",
    "#                 original_state_dict[k] = temp_v\n",
    "            original_state_dict = {}\n",
    "            for k, v in self.model.state_dict().items():\n",
    "                if self.process == 0:\n",
    "                    original_state_dict[k] = v.clone().detach()\n",
    "                dist.broadcast(v, src=0, async_op=True)\n",
    "#                 original_state_dict[k] = v\n",
    "#             if self.process == 0:\n",
    "#                 print('forward start')\n",
    "#                 print(original_state_dict['h1.bias'])\n",
    "            \n",
    "#             self._update_net(original_state_dict)\n",
    "            \n",
    "            self.hey = 10\n",
    "    #         if self.process > 0:\n",
    "            \n",
    "            self.model.train()\n",
    "\n",
    "            support_x, support_y, query_x, query_y = data\n",
    "            support_x = torch.FloatTensor(support_x)\n",
    "            support_y = torch.LongTensor(support_y)\n",
    "            query_x = torch.FloatTensor(query_x)\n",
    "            query_y = torch.LongTensor(query_y)\n",
    "\n",
    "            for i in range(num_updates):\n",
    "                loss, pred = self.model(support_x, support_y)\n",
    "                self.meta_optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.meta_optimizer.step()\n",
    "\n",
    "            loss, pred = self.model(query_x, query_y)\n",
    "            all_grads = autograd.grad(loss, self.model.parameters())#, create_graph=True)\n",
    "            if self.process == 0:\n",
    "                print('after meta gradient batch')\n",
    "                print(self.model.state_dict()['h1.weight'][0, :])#(value_temp, hey_temp)[0])\n",
    "    #         if self.process == 0:\n",
    "    #         for idx in range(len(all_grads)):\n",
    "    #             all_grads[idx].data = torch.zeros_like(all_grads[idx].data)\n",
    "\n",
    "\n",
    "            for idx in range(len(all_grads)):\n",
    "                all_grads[idx].data = torch.zeros_like(all_grads[idx].data)\n",
    "#                 all_grads[idx].data *= 10\n",
    "                dist.all_reduce(all_grads[idx].data, op=dist.ReduceOp.SUM)\n",
    "    #             all_grads[idx].data /= self.world_size\n",
    "\n",
    "            dist.barrier()\n",
    "            if self.process == 0:\n",
    "                self._write_grads(original_state_dict, all_grads)\n",
    "#                 model_queue.get()\n",
    "#                 model_queue[0] = self.model.state_dict()\n",
    "#                 model_dict['params'] = self.model.state_dict()\n",
    "                process_event.set()\n",
    "            \n",
    "    def predict(self, data, num_updates=5):\n",
    "        self.model.eval()\n",
    "        \n",
    "        support_x, support_y, query_x, query_y = data\n",
    "        support_x = torch.FloatTensor(support_x)\n",
    "        support_y = torch.LongTensor(support_y)\n",
    "        query_x = torch.FloatTensor(query_x)\n",
    "        query_y = torch.LongTensor(query_y)\n",
    "        for i in range(num_updates):\n",
    "            loss, pred = self.model(support_x, support_y)\n",
    "            self.meta_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.meta_optimizer.step()\n",
    "        \n",
    "        _, pred = self.model(query_x, query_y)\n",
    "        return pred\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MetaLearner:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.device = \"cpu\"\n",
    "        self.in_dim = 24\n",
    "        self.dropout_rates = [0.5, 0.5, 0.5]#[0.0, 0.25, 0.5, 0.75, 1.0]\n",
    "        self.learners = [Learner(process=i, world_size=len(self.dropout_rates),\n",
    "                                 in_dim=self.in_dim, dropout_rate=dropout_rate) for i, dropout_rate in enumerate(self.dropout_rates)]\n",
    "        self.backend = \"gloo\" if self.device is \"cpu\" else \"nccl\"\n",
    "        \n",
    "        \n",
    "    def init_process(self, process, world_size, data_queue, data_event, model_queue, process_event, address='localhost', port='29500'):\n",
    "        num_updates = 5\n",
    "        os.environ['MASTER_ADDR'] = address\n",
    "        os.environ['MASTER_PORT'] = port\n",
    "        dist.init_process_group(self.backend, rank=process, world_size=world_size)\n",
    "        self.learners[process](num_updates, data_queue, data_event, model_queue, process_event)\n",
    "    \n",
    "    def train(self):\n",
    "        data_queue = Queue()\n",
    "        model_queue = Queue()\n",
    "        manage = Manager()\n",
    "#         [self.learners[0].model.state_dict()]\n",
    "#         model_queue = manage.list({'d': torch.rand(20, 1), 's': torch.rand(20, 1)})\n",
    "#         model_dict = manage.dict()\n",
    "#         temp = self.learners[0].model.state_dict()\n",
    "#         model_dict['params'] = temp#self.learners[0].model.state_dict()\n",
    "#         model_queue.put(self.learners[0].model.state_dict())\n",
    "        data_event = Event() # set to False\n",
    "        process_event = Event() # set to True\n",
    "        process_event.set()\n",
    "        \n",
    "        \n",
    "        num_iters = 5\n",
    "        in_dim = 24\n",
    "        processes = []\n",
    "        for process in range(len(self.dropout_rates)):\n",
    "            processes.append(Process(target=self.init_process, args=(process, len(self.dropout_rates), data_queue, data_event, model_queue, process_event)))\n",
    "            processes[-1].start()\n",
    "            \n",
    "        for batch_idx in range(num_iters):\n",
    "            process_event.wait()\n",
    "            process_event.clear()\n",
    "#             data = np.random.rand(20, self.in_dim)\n",
    "            data = (np.random.rand(20, self.in_dim), np.random.randint(0, 10, (20)), np.random.rand(1, self.in_dim), np.random.randint(0, 10, (1)))\n",
    "            for _ in range(len(self.dropout_rates)):\n",
    "                data_queue.put(data)\n",
    "\n",
    "            data_event.set()\n",
    "            \n",
    "#             model_queue.get()\n",
    "#             print('check here')\n",
    "#             print(q)\n",
    "#             sleep(5)\n",
    "#             print(\"asdasdasdasd \" + str(q.get()))\n",
    "\n",
    "        new_state_dict = self.learners[0].model.state_dict()\n",
    "#             print(self.learners[0].hey)\n",
    "        for p in processes:\n",
    "            p.join()\n",
    "        \n",
    "\n",
    "#             print('hi?')\n",
    "\n",
    "#             print(self.learners[0].process)\n",
    "#             print(self.learners[0].model.state_dict()['h1.bias'])#(value_temp, hey_temp)[0])\n",
    "#             print(\"batch_idx : %d\" % batch_idx)\n",
    "#             self.model_params = self.learners[0].model.parameters()\n",
    "            \n",
    "        \n",
    "#     for gpu, task in enumerate(batch_task):\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = MetaLearner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at top\n",
      "tensor([-0.1923, -0.0400, -0.0980, -0.0544, -0.1803,  0.0819, -0.1830, -0.0130,\n",
      "         0.0710, -0.0688,  0.1158,  0.0257,  0.1122,  0.1310, -0.0901,  0.0742,\n",
      "        -0.0883,  0.0640, -0.1067,  0.0944,  0.0413, -0.0799, -0.1001,  0.0528])\n",
      "after meta gradient batch\n",
      "tensor([-0.1913, -0.0416, -0.1016, -0.0484, -0.1816,  0.0830, -0.1794, -0.0145,\n",
      "         0.0711, -0.0691,  0.1146,  0.0277,  0.1169,  0.1311, -0.0897,  0.0735,\n",
      "        -0.0855,  0.0637, -0.1062,  0.0967,  0.0475, -0.0756, -0.1039,  0.0555])\n",
      "after meta gradient and loaded batch\n",
      "tensor([-0.1923, -0.0400, -0.0980, -0.0544, -0.1803,  0.0819, -0.1830, -0.0130,\n",
      "         0.0710, -0.0688,  0.1158,  0.0257,  0.1122,  0.1310, -0.0901,  0.0742,\n",
      "        -0.0883,  0.0640, -0.1067,  0.0944,  0.0413, -0.0799, -0.1001,  0.0528])\n",
      "after meta gradient batch\n",
      "tensor([-0.1823, -0.0300, -0.0880, -0.0444, -0.1703,  0.0919, -0.1730, -0.0030,\n",
      "         0.0810, -0.0588,  0.1258,  0.0357,  0.1222,  0.1410, -0.0801,  0.0842,\n",
      "        -0.0783,  0.0740, -0.0967,  0.1044,  0.0513, -0.0699, -0.0901,  0.0628])\n",
      "at top\n",
      "tensor([-0.1823, -0.0300, -0.0880, -0.0444, -0.1703,  0.0919, -0.1730, -0.0030,\n",
      "         0.0810, -0.0588,  0.1258,  0.0357,  0.1222,  0.1410, -0.0801,  0.0842,\n",
      "        -0.0783,  0.0740, -0.0967,  0.1044,  0.0513, -0.0699, -0.0901,  0.0628])\n",
      "after meta gradient batch\n",
      "tensor([-0.1788, -0.0268, -0.0840, -0.0392, -0.1632,  0.0967, -0.1672,  0.0008,\n",
      "         0.0886, -0.0583,  0.1307,  0.0371,  0.1282,  0.1390, -0.0709,  0.0872,\n",
      "        -0.0705,  0.0750, -0.0883,  0.1077,  0.0573, -0.0667, -0.0846,  0.0712])\n",
      "after meta gradient and loaded batch\n",
      "tensor([-0.1823, -0.0300, -0.0880, -0.0444, -0.1703,  0.0919, -0.1730, -0.0030,\n",
      "         0.0810, -0.0588,  0.1258,  0.0357,  0.1222,  0.1410, -0.0801,  0.0842,\n",
      "        -0.0783,  0.0740, -0.0967,  0.1044,  0.0513, -0.0699, -0.0901,  0.0628])\n",
      "after meta gradient batch\n",
      "tensor([-0.1747, -0.0203, -0.0811, -0.0344, -0.1604,  0.1018, -0.1631,  0.0040,\n",
      "         0.0894, -0.0495,  0.1358,  0.0453,  0.1316,  0.1496, -0.0701,  0.0942,\n",
      "        -0.0692,  0.0838, -0.0878,  0.1122,  0.0609, -0.0600, -0.0822,  0.0711])\n",
      "at top\n",
      "tensor([-0.1747, -0.0203, -0.0811, -0.0344, -0.1604,  0.1018, -0.1631,  0.0040,\n",
      "         0.0894, -0.0495,  0.1358,  0.0453,  0.1316,  0.1496, -0.0701,  0.0942,\n",
      "        -0.0692,  0.0838, -0.0878,  0.1122,  0.0609, -0.0600, -0.0822,  0.0711])\n",
      "after meta gradient batch\n",
      "tensor([-0.1725, -0.0220, -0.0804, -0.0344, -0.1614,  0.1043, -0.1627,  0.0053,\n",
      "         0.0906, -0.0493,  0.1440,  0.0459,  0.1273,  0.1523, -0.0685,  0.0944,\n",
      "        -0.0698,  0.0817, -0.0896,  0.1097,  0.0569, -0.0559, -0.0759,  0.0709])\n",
      "after meta gradient and loaded batch\n",
      "tensor([-0.1747, -0.0203, -0.0811, -0.0344, -0.1604,  0.1018, -0.1631,  0.0040,\n",
      "         0.0894, -0.0495,  0.1358,  0.0453,  0.1316,  0.1496, -0.0701,  0.0942,\n",
      "        -0.0692,  0.0838, -0.0878,  0.1122,  0.0609, -0.0600, -0.0822,  0.0711])\n",
      "after meta gradient batch\n",
      "tensor([-0.1685, -0.0125, -0.0754, -0.0264, -0.1514,  0.1096, -0.1555,  0.0098,\n",
      "         0.0970, -0.0409,  0.1440,  0.0527,  0.1391,  0.1568, -0.0622,  0.1029,\n",
      "        -0.0620,  0.0917, -0.0806,  0.1182,  0.0686, -0.0520, -0.0760,  0.0781])\n",
      "at top\n",
      "tensor([-0.1685, -0.0125, -0.0754, -0.0264, -0.1514,  0.1096, -0.1555,  0.0098,\n",
      "         0.0970, -0.0409,  0.1440,  0.0527,  0.1391,  0.1568, -0.0622,  0.1029,\n",
      "        -0.0620,  0.0917, -0.0806,  0.1182,  0.0686, -0.0520, -0.0760,  0.0781])\n",
      "after meta gradient batch\n",
      "tensor([-0.1682, -0.0146, -0.0769, -0.0254, -0.1528,  0.1101, -0.1551,  0.0143,\n",
      "         0.0982, -0.0411,  0.1382,  0.0541,  0.1392,  0.1566, -0.0642,  0.1024,\n",
      "        -0.0645,  0.0886, -0.0766,  0.1192,  0.0669, -0.0534, -0.0761,  0.0753])\n",
      "after meta gradient and loaded batch\n",
      "tensor([-0.1685, -0.0125, -0.0754, -0.0264, -0.1514,  0.1096, -0.1555,  0.0098,\n",
      "         0.0970, -0.0409,  0.1440,  0.0527,  0.1391,  0.1568, -0.0622,  0.1029,\n",
      "        -0.0620,  0.0917, -0.0806,  0.1182,  0.0686, -0.0520, -0.0760,  0.0781])\n",
      "after meta gradient batch\n",
      "tensor([-0.1644, -0.0070, -0.0750, -0.0238, -0.1526,  0.1140, -0.1517,  0.0107,\n",
      "         0.1009, -0.0389,  0.1492,  0.0579,  0.1451,  0.1615, -0.0582,  0.1078,\n",
      "        -0.0567,  0.0961, -0.0777,  0.1217,  0.0740, -0.0471, -0.0767,  0.0825])\n",
      "at top\n",
      "tensor([-0.1644, -0.0070, -0.0750, -0.0238, -0.1526,  0.1140, -0.1517,  0.0107,\n",
      "         0.1009, -0.0389,  0.1492,  0.0579,  0.1451,  0.1615, -0.0582,  0.1078,\n",
      "        -0.0567,  0.0961, -0.0777,  0.1217,  0.0740, -0.0471, -0.0767,  0.0825])\n",
      "after meta gradient batch\n",
      "tensor([-0.1654, -0.0102, -0.0755, -0.0269, -0.1540,  0.1132, -0.1532,  0.0104,\n",
      "         0.1009, -0.0414,  0.1467,  0.0588,  0.1473,  0.1616, -0.0609,  0.1057,\n",
      "        -0.0584,  0.0962, -0.0788,  0.1223,  0.0753, -0.0490, -0.0789,  0.0787])\n",
      "after meta gradient and loaded batch\n",
      "tensor([-0.1644, -0.0070, -0.0750, -0.0238, -0.1526,  0.1140, -0.1517,  0.0107,\n",
      "         0.1009, -0.0389,  0.1492,  0.0579,  0.1451,  0.1615, -0.0582,  0.1078,\n",
      "        -0.0567,  0.0961, -0.0777,  0.1217,  0.0740, -0.0471, -0.0767,  0.0825])\n",
      "after meta gradient batch\n",
      "tensor([-0.1595, -0.0012, -0.0735, -0.0202, -0.1526,  0.1186, -0.1484,  0.0115,\n",
      "         0.1071, -0.0349,  0.1554,  0.0629,  0.1515,  0.1656, -0.0533,  0.1126,\n",
      "        -0.0501,  0.1016, -0.0745,  0.1249,  0.0794, -0.0416, -0.0756,  0.0871])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-2:\n",
      "Process Process-4:\n",
      "Process Process-3:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-4-ed64bb537d9b>\", line 17, in init_process\n",
      "    self.learners[process](num_updates, data_queue, data_event, model_queue, process_event)\n",
      "  File \"<ipython-input-4-ed64bb537d9b>\", line 17, in init_process\n",
      "    self.learners[process](num_updates, data_queue, data_event, model_queue, process_event)\n",
      "  File \"<ipython-input-4-ed64bb537d9b>\", line 17, in init_process\n",
      "    self.learners[process](num_updates, data_queue, data_event, model_queue, process_event)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 541, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 541, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 541, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-3-cea4a9a7ff3d>\", line 49, in forward\n",
      "    data_event.wait()\n",
      "  File \"<ipython-input-3-cea4a9a7ff3d>\", line 49, in forward\n",
      "    data_event.wait()\n",
      "  File \"<ipython-input-3-cea4a9a7ff3d>\", line 49, in forward\n",
      "    data_event.wait()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/synchronize.py\", line 350, in wait\n",
      "    self._cond.wait(timeout)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/synchronize.py\", line 350, in wait\n",
      "    self._cond.wait(timeout)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/synchronize.py\", line 350, in wait\n",
      "    self._cond.wait(timeout)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/synchronize.py\", line 262, in wait\n",
      "    return self._wait_semaphore.acquire(True, timeout)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/synchronize.py\", line 262, in wait\n",
      "    return self._wait_semaphore.acquire(True, timeout)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/synchronize.py\", line 262, in wait\n",
      "    return self._wait_semaphore.acquire(True, timeout)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-7140e895fef4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-ed64bb537d9b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;31m#             print(self.learners[0].hey)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprocesses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_pid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a child process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a started process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0m_children\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     46\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;31m# This shouldn't block if wait() returned successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWNOHANG\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0;31m# Child process not yet created. See #1731717\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "M.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before meta gradient batch\n",
      "tensor([-0.1913, -0.0416, -0.1016, -0.0484, -0.1816,  0.0830, -0.1794, -0.0145,\n",
      "         0.0711, -0.0691,  0.1146,  0.0277,  0.1169,  0.1311, -0.0897,  0.0735,\n",
      "        -0.0855,  0.0637, -0.1062,  0.0967,  0.0475, -0.0756, -0.1039,  0.0555])\n",
      "after meta gradient batch\n",
      "tensor([-0.1813, -0.0316, -0.0916, -0.0384, -0.1716,  0.0930, -0.1694, -0.0045,\n",
      "         0.0811, -0.0591,  0.1246,  0.0377,  0.1269,  0.1411, -0.0797,  0.0835,\n",
      "        -0.0755,  0.0737, -0.0962,  0.1067,  0.0575, -0.0656, -0.0939,  0.0655])\n",
      "before meta gradient batch\n",
      "tensor([-0.1809, -0.0310, -0.0910, -0.0364, -0.1675,  0.0950, -0.1657, -0.0036,\n",
      "         0.0864, -0.0609,  0.1271,  0.0364,  0.1299,  0.1367, -0.0736,  0.0846,\n",
      "        -0.0699,  0.0718, -0.0912,  0.1073,  0.0607, -0.0649, -0.0916,  0.0703])\n",
      "after meta gradient batch\n",
      "tensor([-0.1734, -0.0223, -0.0838, -0.0272, -0.1581,  0.1039, -0.1569,  0.0040,\n",
      "         0.0942, -0.0509,  0.1363,  0.0448,  0.1382,  0.1466, -0.0642,  0.0939,\n",
      "        -0.0617,  0.0814, -0.0832,  0.1149,  0.0692, -0.0553, -0.0840,  0.0781])\n",
      "before meta gradient batch\n",
      "tensor([-0.1726, -0.0243, -0.0844, -0.0278, -0.1599,  0.1048, -0.1573,  0.0043,\n",
      "         0.0935, -0.0518,  0.1419,  0.0442,  0.1336,  0.1487, -0.0640,  0.0941,\n",
      "        -0.0635,  0.0785, -0.0858,  0.1117,  0.0647, -0.0528, -0.0794,  0.0772])\n",
      "after meta gradient batch\n",
      "tensor([-0.1679, -0.0184, -0.0830, -0.0219, -0.1601,  0.1115, -0.1506,  0.0068,\n",
      "         0.0948, -0.0536,  0.1467,  0.0506,  0.1389,  0.1523, -0.0581,  0.0956,\n",
      "        -0.0576,  0.0843, -0.0810,  0.1175,  0.0698, -0.0469, -0.0738,  0.0812])\n",
      "before meta gradient batch\n",
      "tensor([-0.1719, -0.0237, -0.0877, -0.0262, -0.1655,  0.1067, -0.1547,  0.0057,\n",
      "         0.0922, -0.0570,  0.1390,  0.0482,  0.1338,  0.1478, -0.0632,  0.0916,\n",
      "        -0.0635,  0.0780, -0.0819,  0.1147,  0.0638, -0.0519, -0.0795,  0.0738])\n",
      "after meta gradient batch\n",
      "tensor([-0.1690, -0.0197, -0.0920, -0.0257, -0.1704,  0.1100, -0.1518,  0.0021,\n",
      "         0.0916, -0.0615,  0.1412,  0.0525,  0.1380,  0.1487, -0.0615,  0.0909,\n",
      "        -0.0594,  0.0801, -0.0807,  0.1181,  0.0670, -0.0491, -0.0803,  0.0760])\n",
      "before meta gradient batch\n",
      "tensor([-0.1678, -0.0203, -0.0902, -0.0263, -0.1712,  0.1104, -0.1528,  0.0032,\n",
      "         0.0928, -0.0615,  0.1421,  0.0543,  0.1409,  0.1497, -0.0630,  0.0906,\n",
      "        -0.0598,  0.0817, -0.0806,  0.1187,  0.0693, -0.0511, -0.0813,  0.0746])\n",
      "after meta gradient batch\n",
      "tensor([-0.1636, -0.0155, -0.0914, -0.0239, -0.1740,  0.1144, -0.1502,  0.0002,\n",
      "         0.0964, -0.0618,  0.1467,  0.0587,  0.1461,  0.1508, -0.0592,  0.0909,\n",
      "        -0.0537,  0.0862, -0.0786,  0.1219,  0.0731, -0.0466, -0.0799,  0.0776])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-2:\n",
      "Process Process-3:\n",
      "Process Process-4:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-4-ed64bb537d9b>\", line 17, in init_process\n",
      "    self.learners[process](num_updates, data_queue, data_event, model_queue, process_event)\n",
      "  File \"<ipython-input-4-ed64bb537d9b>\", line 17, in init_process\n",
      "    self.learners[process](num_updates, data_queue, data_event, model_queue, process_event)\n",
      "  File \"<ipython-input-4-ed64bb537d9b>\", line 17, in init_process\n",
      "    self.learners[process](num_updates, data_queue, data_event, model_queue, process_event)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 541, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 541, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 541, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-3-f40069bd2526>\", line 49, in forward\n",
      "    data_event.wait()\n",
      "  File \"<ipython-input-3-f40069bd2526>\", line 49, in forward\n",
      "    data_event.wait()\n",
      "  File \"<ipython-input-3-f40069bd2526>\", line 49, in forward\n",
      "    data_event.wait()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/synchronize.py\", line 350, in wait\n",
      "    self._cond.wait(timeout)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/synchronize.py\", line 350, in wait\n",
      "    self._cond.wait(timeout)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/synchronize.py\", line 350, in wait\n",
      "    self._cond.wait(timeout)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/synchronize.py\", line 262, in wait\n",
      "    return self._wait_semaphore.acquire(True, timeout)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/synchronize.py\", line 262, in wait\n",
      "    return self._wait_semaphore.acquire(True, timeout)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/synchronize.py\", line 262, in wait\n",
      "    return self._wait_semaphore.acquire(True, timeout)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-6-7140e895fef4>\", line 1, in <module>\n",
      "    M.train()\n",
      "  File \"<ipython-input-4-ed64bb537d9b>\", line 60, in train\n",
      "    p.join()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 140, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/popen_fork.py\", line 48, in wait\n",
      "    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/popen_fork.py\", line 28, in poll\n",
      "    pid, sts = os.waitpid(self.pid, flag)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2040, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/inspect.py\", line 1495, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/inspect.py\", line 1453, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/posixpath.py\", line 389, in realpath\n",
      "    return abspath(path)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/posixpath.py\", line 378, in abspath\n",
      "    return normpath(path)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/posixpath.py\", line 363, in normpath\n",
      "    path = sep.join(comps)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "M.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.7076, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 0\n",
      "tensor(2.7144, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 1\n",
      "tensor(2.2456, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 2\n",
      "tensor(2.5642, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 3\n",
      "tensor(2.6849, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 4\n"
     ]
    }
   ],
   "source": [
    "M.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5149, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 0\n",
      "tensor(2.4864, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 1\n",
      "tensor(2.2415, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 2\n",
      "tensor(2.4620, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 3\n",
      "tensor(2.5039, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 4\n",
      "tensor(2.2008, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 5\n",
      "tensor(2.5494, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 6\n",
      "tensor(2.1926, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 7\n",
      "tensor(2.5703, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 8\n",
      "tensor(2.5106, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 9\n",
      "tensor(2.5672, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 10\n",
      "tensor(2.1619, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 11\n",
      "tensor(2.5062, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 12\n",
      "tensor(2.4929, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 13\n",
      "tensor(2.5846, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 14\n",
      "tensor(2.2494, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 15\n",
      "tensor(2.4588, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 16\n",
      "tensor(2.5083, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 17\n",
      "tensor(2.2435, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 18\n",
      "tensor(2.2194, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 19\n",
      "tensor(2.5170, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 20\n",
      "tensor(2.4620, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 21\n",
      "tensor(2.4864, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 22\n",
      "tensor(2.5211, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 23\n",
      "tensor(2.1633, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 24\n",
      "tensor(2.5340, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 25\n",
      "tensor(2.2346, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 26\n",
      "tensor(2.4857, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 27\n",
      "tensor(2.5548, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 28\n",
      "tensor(2.5149, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 29\n",
      "tensor(2.5206, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 30\n",
      "tensor(2.2277, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 31\n",
      "tensor(2.5135, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 32\n",
      "tensor(2.5369, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 33\n",
      "tensor(2.5083, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 34\n",
      "tensor(2.5228, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 35\n",
      "tensor(2.4932, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 36\n",
      "tensor(2.5242, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 37\n",
      "tensor(2.2157, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 38\n",
      "tensor(2.5149, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 39\n",
      "tensor(2.4451, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 40\n",
      "tensor(2.1596, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 41\n",
      "tensor(2.2366, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 42\n",
      "tensor(2.2569, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 43\n",
      "tensor(2.5255, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 44\n",
      "tensor(2.5646, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 45\n",
      "tensor(2.2891, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 46\n",
      "tensor(2.5296, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 47\n",
      "tensor(2.5278, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 48\n",
      "tensor(2.5522, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 49\n",
      "tensor(2.1829, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 50\n",
      "tensor(2.2261, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 51\n",
      "tensor(2.5631, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 52\n",
      "tensor(2.2311, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 53\n",
      "tensor(2.5485, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 54\n",
      "tensor(2.1765, grad_fn=<NllLossBackward>)\n",
      "batch_idx : 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-171:\n",
      "Process Process-170:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-4-2f27a93cfa97>\", line 19, in init_process\n",
      "    os.environ['MASTER_ADDR'] = address\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-4-2f27a93cfa97>\", line 21, in init_process\n",
      "    dist.init_process_group(self.backend, rank=process, world_size=world_size)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/distributed/distributed_c10d.py\", line 400, in init_process_group\n",
      "    store, rank, world_size = next(rendezvous(url))\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/distributed/rendezvous.py\", line 143, in _env_rendezvous_handler\n",
      "    store = TCPStore(master_addr, master_port, world_size, start_daemon)\n",
      "KeyboardInterrupt\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-6-7140e895fef4>\", line 1, in <module>\n",
      "    M.train()\n",
      "  File \"<ipython-input-4-2f27a93cfa97>\", line 39, in train\n",
      "    p.join()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 140, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/popen_fork.py\", line 48, in wait\n",
      "    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/popen_fork.py\", line 28, in poll\n",
      "    pid, sts = os.waitpid(self.pid, flag)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2040, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/inspect.py\", line 1495, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/inspect.py\", line 1457, in getframeinfo\n",
      "    lines, lnum = findsource(frame)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 173, in findsource\n",
      "    file = getsourcefile(object) or getfile(object)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/inspect.py\", line 70, in ismodule\n",
      "    return isinstance(object, types.ModuleType)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "M.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "x = pd.DataFrame(np.random.rand(20, 40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Get(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Get).__init__()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return 10\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.FloatTensor(pd.DataFrame(np.random.rand(20, 40)).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = torch.utils.data.DataLoader(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20, 40])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dd)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
